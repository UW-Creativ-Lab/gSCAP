{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T03:09:05.646575Z",
     "start_time": "2018-09-25T03:09:00.686200Z"
    },
    "code_folding": [
     22,
     29
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, Luke Waninger!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import synapseclient\n",
    "from synapseclient import Activity, Project, Folder, File, Table, Schema, as_table_columns\n",
    "\n",
    "# set the user's home directory as the data directory\n",
    "data_dir = os.path.join(str(Path.home()), '.gscat')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "    \n",
    "syn = synapseclient.Synapse()\n",
    "syn.login()\n",
    "\n",
    "storage = syn.get(Project(name='GSCAP Data'))\n",
    "source_files = syn.store(Folder(name='source_files', parent=storage, downloadPath=data_dir))\n",
    "dpath = lambda s: os.path.join(data_dir, s)\n",
    "\n",
    "def isnum(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def isstr(x):\n",
    "    try:\n",
    "        str(x)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Zipcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T03:09:10.048805Z",
     "start_time": "2018-09-25T03:09:05.649268Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zname = 'zb16totals'\n",
    "url =  'https://www2.census.gov/programs-surveys/cbp/datasets/2016/zbp16totals.zip'\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.ok:\n",
    "    t_path = dpath('2017_Gaz_zcta_national.txt')\n",
    "    f = io.BytesIO(response.content)\n",
    "\n",
    "    with zipfile.ZipFile(f, 'r') as f:\n",
    "        contents = [\n",
    "            dict(\n",
    "                name=name[:name.find('.')],\n",
    "                data=f.read(name),\n",
    "                ext=name[name.find('.')+1:]\n",
    "            )\n",
    "            for name in f.namelist()\n",
    "        ]\n",
    "\n",
    "    for fi in contents:        \n",
    "        with io.BytesIO(fi['data']) as fi_:\n",
    "            a = pd.read_csv(fi_)  \n",
    "        \n",
    "        a.to_csv(dpath(zname))\n",
    "        cbp_totals_syn = syn.setProvenance(\n",
    "            syn.store(File(name=zname, path=dpath(zname), parent=source_files)),\n",
    "            activity=Activity(used=[dict(name='US Census Bureau', url=url)])\n",
    "        )\n",
    "        \n",
    "        a.drop(columns=['name', 'empflag', 'emp_nf', 'emp', 'qp1_nf', 'qp1', 'ap_nf', 'ap', 'est'], inplace=True)\n",
    "        a.rename(columns={'cty_name':'county', 'zip':'zipcode'}, inplace=True)\n",
    "        \n",
    "        a.city = [str(x).title() if isstr(x) else x for x in a.city]\n",
    "        a.county = [str(x).title() if isstr(x) else x for x in a.county]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T03:09:15.084379Z",
     "start_time": "2018-09-25T03:09:10.050946Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      " Uploading file to Synapse storage \n",
      "##################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zname = '2017_national_zipcodes.csv'\n",
    "url =  'http://www2.census.gov/geo/docs/maps-data/data/gazetteer/2017_Gazetteer/2017_Gaz_zcta_national.zip'\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.ok:\n",
    "    t_path = dpath('2017_Gaz_zcta_national.txt')\n",
    "    f = io.BytesIO(response.content)\n",
    "\n",
    "    with zipfile.ZipFile(f, 'r') as f:\n",
    "        f.extractall(path=data_dir)\n",
    "\n",
    "    b = pd.read_csv(t_path, sep='\\t')\n",
    "    \n",
    "    name = '2017_Gaz_zcta_national.csv'    \n",
    "    b.to_csv(dpath(name))\n",
    "    \n",
    "    zips_syn = syn.setProvenance(\n",
    "        syn.store(File(name=name, path=dpath(name), parent=source_files)),\n",
    "        activity=Activity(used=[dict(name='US Census Bureau', url=url)])\n",
    "    )\n",
    "    \n",
    "    b.columns = [s.strip() for s in b.columns]\n",
    "    b = b.loc[:, ['GEOID', 'INTPTLAT', 'INTPTLONG']]\n",
    "    b.columns = ['zipcode', 'lat', 'lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T03:09:17.741462Z",
     "start_time": "2018-09-25T03:09:15.086838Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sname = 'state_codes.csv'\n",
    "state_codes = pd.read_csv(dpath(sname))\n",
    "state_codes_syn = syn.store(File(name=sname, path=dpath(sname), parent=source_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T03:09:17.786080Z",
     "start_time": "2018-09-25T03:09:17.743786Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = pd.merge(a, b, on='zipcode')\n",
    "d = pd.merge(d, state_codes, left_on='stabbr', right_on='Code')\n",
    "d = d.drop(columns='Code')\n",
    "d = d.rename(columns={'State':'state'})\n",
    "\n",
    "d.lat = np.round(d.lat, 5)\n",
    "d.lon = np.round(d.lon, 5)\n",
    "\n",
    "d = d[['zipcode', 'city', 'county', 'state', 'stabbr', 'lat', 'lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T03:11:30.341298Z",
     "start_time": "2018-09-25T03:11:29.743396Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "timezones = syn.get('syn16810024')\n",
    "tz = pd.read_csv(timezones.path)\n",
    "tz = tz.rename(columns={'zip':'zipcode'})\n",
    "\n",
    "e = pd.merge(d, tz.loc[:, ['zipcode', 'timezone']], on=['zipcode'])\n",
    "\n",
    "e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "zips = syn.setProvenance(\n",
    "    syn.store(Table(\n",
    "        Schema(name='zipcodes', columns=as_table_columns(e), parent=storage), e)\n",
    "    ),\n",
    "    activity=Activity(\n",
    "        name='zipcode collation',\n",
    "        description='Collecting zipcodes, counties, states, and geo-locations into a single table.',\n",
    "        used=['syn16816617', 'syn16816613', 'syn16816612', 'syn16810024'],\n",
    "        executed=[dict(\n",
    "            name='synapse_project_setup.ipynb', \n",
    "            url='https://github.com/lukeWaninger/GSCAT/blob/master/notebooks/synapse_project_setup.ipynb'\n",
    "        )]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T03:41:04.594844Z",
     "start_time": "2018-09-25T03:19:10.319874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################\n",
      " Uploading file to Synapse storage \n",
      "##################################################\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] /home/luke/anaconda3/envs/bright/lib/python3.6/site-packages/synapseclient/multipart_upload.py:301: UserWarning: The presigned upload URL has expired. Restarting upload...\n",
      "\n",
      "  warnings.warn(\"The presigned upload URL has expired. Restarting upload...\\n\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db_name = 'weather_cache.sqlite'\n",
    "weather_cache = syn.setProvenance(\n",
    "    syn.store(File(name=db_name, path=dpath(db_name), parent=storage)),\n",
    "    activity=Activity(\n",
    "        used=[dict(name='DarkSky API', url='https://darksky.net/dev/docs')],\n",
    "        executed=[dict(name='weather.py', url='https://github.com/lukeWaninger/GSCAT/blob/master/weather.py')]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleMaps cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bright]",
   "language": "python",
   "name": "conda-env-bright-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
